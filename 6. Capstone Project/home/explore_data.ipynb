{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "import configparser\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DateType, StructType, StructField, TimestampType\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "spark = SparkSession.builder \\\n",
    "            .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\") \\\n",
    "            .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "            .enableHiveSupport().getOrCreate()\n",
    "input_data = ''\n",
    "immigration_data_path = input_data + \"sas_data\"\n",
    "df = spark.read.parquet(immigration_data_path)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cicid=5748517.0, i94yr=2016.0, i94mon=4.0, i94cit=245.0, i94res=438.0, i94port='LOS', arrdate=20574.0, i94mode=1.0, i94addr='CA', depdate=20582.0, i94bir=40.0, i94visa=1.0, count=1.0, dtadfile='20160430', visapost='SYD', occup=None, entdepa='G', entdepd='O', entdepu=None, matflag='M', biryear=1976.0, dtaddto='10292016', gender='F', insnum=None, airline='QF', admnum=94953870030.0, fltno='00011', visatype='B1'),\n",
       " Row(cicid=5748518.0, i94yr=2016.0, i94mon=4.0, i94cit=245.0, i94res=438.0, i94port='LOS', arrdate=20574.0, i94mode=1.0, i94addr='NV', depdate=20591.0, i94bir=32.0, i94visa=1.0, count=1.0, dtadfile='20160430', visapost='SYD', occup=None, entdepa='G', entdepd='O', entdepu=None, matflag='M', biryear=1984.0, dtaddto='10292016', gender='F', insnum=None, airline='VA', admnum=94955622830.0, fltno='00007', visatype='B1'),\n",
       " Row(cicid=5748519.0, i94yr=2016.0, i94mon=4.0, i94cit=245.0, i94res=438.0, i94port='LOS', arrdate=20574.0, i94mode=1.0, i94addr='WA', depdate=20582.0, i94bir=29.0, i94visa=1.0, count=1.0, dtadfile='20160430', visapost='SYD', occup=None, entdepa='G', entdepd='O', entdepu=None, matflag='M', biryear=1987.0, dtaddto='10292016', gender='M', insnum=None, airline='DL', admnum=94956406530.0, fltno='00040', visatype='B1'),\n",
       " Row(cicid=5748520.0, i94yr=2016.0, i94mon=4.0, i94cit=245.0, i94res=438.0, i94port='LOS', arrdate=20574.0, i94mode=1.0, i94addr='WA', depdate=20588.0, i94bir=29.0, i94visa=1.0, count=1.0, dtadfile='20160430', visapost='SYD', occup=None, entdepa='G', entdepd='O', entdepu=None, matflag='M', biryear=1987.0, dtaddto='10292016', gender='F', insnum=None, airline='DL', admnum=94956451430.0, fltno='00040', visatype='B1'),\n",
       " Row(cicid=5748521.0, i94yr=2016.0, i94mon=4.0, i94cit=245.0, i94res=438.0, i94port='LOS', arrdate=20574.0, i94mode=1.0, i94addr='WA', depdate=20588.0, i94bir=28.0, i94visa=1.0, count=1.0, dtadfile='20160430', visapost='SYD', occup=None, entdepa='G', entdepd='O', entdepu=None, matflag='M', biryear=1988.0, dtaddto='10292016', gender='M', insnum=None, airline='DL', admnum=94956388130.0, fltno='00040', visatype='B1')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203307"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_data_path = input_data + \"sas_data/part-00013-b9542815-7a8d-45fc-9c67-c9c5007ad0d4-c000.snappy.parquet\"\n",
    "df = spark.read.parquet(immigration_data_path)\n",
    "df = df.filter(df.cicid.isNotNull() & df.arrdate.isNotNull() & df.depdate.isNotNull())\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rename_columns(df, new_columns):\n",
    "    \"\"\"Rename columns.\n",
    "    Input:\n",
    "        Data frame that needs to rename columns.\n",
    "        List of new columns name.\n",
    "    Output:\n",
    "        Data frame with new columns name.\n",
    "    \"\"\"\n",
    "    for original, new in zip(df.columns, new_columns):\n",
    "        df = df.withColumnRenamed(original, new)\n",
    "    return df\n",
    "\n",
    "def to_date_func(date):\n",
    "    if date is not None:\n",
    "        return (datetime(1960,1,1) + timedelta(days=int(date)))\n",
    "to_date_func_udf = udf(to_date_func, DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_immigration = df.select('cicid', 'i94yr', 'i94mon', 'i94port', 'i94addr', \\\n",
    "                                 'arrdate', 'depdate', 'i94mode', 'i94visa') \\\n",
    "                        .distinct() \\\n",
    "                         .withColumn(\"immigration_id\", monotonically_increasing_id())\n",
    "    \n",
    "new_columns = ['cic_id', 'arrival_year', 'arrival_month', 'city_code', 'state_code',\\\n",
    "               'arrival_date', 'departure_date', 'mode', 'visa']\n",
    "\n",
    "fact_immigration = rename_columns(fact_immigration, new_columns)\n",
    "\n",
    "fact_immigration = fact_immigration.withColumn('country', lit('United States'))\n",
    "\n",
    "fact_immigration = fact_immigration.withColumn('arrival_date', \\\n",
    "                                    to_date_func_udf(col('arrival_date')))\n",
    "\n",
    "fact_immigration = fact_immigration.withColumn('departure_date', \\\n",
    "                                    to_date_func_udf(col('departure_date')))\n",
    "\n",
    "# fact_immigration.write.mode(\"overwrite\").partitionBy('state_code')\\\n",
    "#                 .parquet(path=output_data + 'fact_immigration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2016, 4, 29)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrival_date = fact_immigration.select('arrival_date').rdd.flatMap(lambda x: x).collect()\n",
    "departure_date = fact_immigration.select('departure_date').rdd.flatMap(lambda x: x).collect()\n",
    "date = arrival_date + departure_date\n",
    "date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406614"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "406614"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = spark.createDataFrame(date, DateType())\n",
    "time = rename_columns(time, ['date'])\n",
    "time.printSchema()\n",
    "time.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+---+----+-----+----+-------+\n",
      "|      date|hour|day|week|month|year|weekday|\n",
      "+----------+----+---+----+-----+----+-------+\n",
      "|2016-04-28|   0| 28|  17|    4|2016|      4|\n",
      "|2016-06-01|   0|  1|  22|    6|2016|      3|\n",
      "|2016-05-01|   0|  1|  17|    5|2016|      7|\n",
      "|2016-07-08|   0|  8|  27|    7|2016|      5|\n",
      "|2015-04-25|   0| 25|  17|    4|2015|      6|\n",
      "|2016-01-29|   0| 29|   4|    1|2016|      5|\n",
      "|2015-04-03|   0|  3|  14|    4|2015|      5|\n",
      "|2016-04-09|   0|  9|  14|    4|2016|      6|\n",
      "|2016-06-02|   0|  2|  22|    6|2016|      4|\n",
      "|2016-03-11|   0| 11|  10|    3|2016|      5|\n",
      "|2016-07-12|   0| 12|  28|    7|2016|      2|\n",
      "|2016-05-14|   0| 14|  19|    5|2016|      6|\n",
      "|2016-08-09|   0|  9|  32|    8|2016|      2|\n",
      "|2016-04-30|   0| 30|  17|    4|2016|      6|\n",
      "|2016-08-03|   0|  3|  31|    8|2016|      3|\n",
      "|2016-02-04|   0|  4|   5|    2|2016|      4|\n",
      "|2016-06-09|   0|  9|  23|    6|2016|      4|\n",
      "|2016-04-10|   0| 10|  14|    4|2016|      7|\n",
      "|2016-05-23|   0| 23|  21|    5|2016|      1|\n",
      "|2016-02-05|   0|  5|   5|    2|2016|      5|\n",
      "+----------+----+---+----+-----+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_time = time.select('date') \\\n",
    "                .withColumn('hour', hour(time['date'])) \\\n",
    "                .withColumn('day', dayofmonth(time['date'])) \\\n",
    "                .withColumn('week', weekofyear(time['date'])) \\\n",
    "                .withColumn('month', month(time['date'])) \\\n",
    "                .withColumn('year', year(time['date'])) \\\n",
    "                .withColumn('weekday', (dayofweek(time['date'])+5)%7+1) \\\n",
    "                .distinct()\n",
    "dim_time.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203307"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_personal_information = df.select('cicid', 'i94cit', 'i94res', \\\n",
    "                                  'biryear', 'gender').distinct() \\\n",
    "                          .withColumn(\"immi_personal_id\", monotonically_increasing_id())\n",
    "    \n",
    "# rename to meaningful columns name\n",
    "new_columns = ['cic_id', 'citizen_country', 'residence_country', \\\n",
    "               'birth_year', 'gender']\n",
    "dim_personal_information = rename_columns(dim_personal_information, new_columns)\n",
    "dim_personal_information.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(City='Silver Spring', State='Maryland', Median Age='33.8', Male Population='40601', Female Population='41862', Total Population='82463', Number of Veterans='1562', Foreign-born='30908', Average Household Size='2.6', State Code='MD', Race='Hispanic or Latino', Count='25924'),\n",
       " Row(City='Quincy', State='Massachusetts', Median Age='41.0', Male Population='44129', Female Population='49500', Total Population='93629', Number of Veterans='4147', Foreign-born='32935', Average Household Size='2.39', State Code='MA', Race='White', Count='58723'),\n",
       " Row(City='Hoover', State='Alabama', Median Age='38.5', Male Population='38040', Female Population='46799', Total Population='84839', Number of Veterans='4819', Foreign-born='8229', Average Household Size='2.58', State Code='AL', Race='Asian', Count='4759'),\n",
       " Row(City='Rancho Cucamonga', State='California', Median Age='34.5', Male Population='88127', Female Population='87105', Total Population='175232', Number of Veterans='5821', Foreign-born='33878', Average Household Size='3.18', State Code='CA', Race='Black or African-American', Count='24437'),\n",
       " Row(City='Newark', State='New Jersey', Median Age='34.6', Male Population='138040', Female Population='143873', Total Population='281913', Number of Veterans='5829', Foreign-born='86253', Average Household Size='2.73', State Code='NJ', Race='White', Count='76402')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = ''\n",
    "demographics_data_path = input_data + 'us-cities-demographics.csv'\n",
    "df = spark.read.options(header=True, delimiter=';').csv(demographics_data_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------------------+---------------+-----------------+----------------+\n",
      "|state_code|    state_name|        median_age|male_population|female_population|total_population|\n",
      "+----------+--------------+------------------+---------------+-----------------+----------------+\n",
      "|        MT|       Montana|              35.5|        87707.0|          93587.0|        181294.0|\n",
      "|        NC|North Carolina|              35.1|      1466105.0|        1594094.0|       3060199.0|\n",
      "|        MD|      Maryland|35.900000000000006|       627951.0|         684178.0|       1312129.0|\n",
      "|        CO|      Colorado|              36.8|      1454619.0|        1481050.0|       2935669.0|\n",
      "|        CT|   Connecticut|             34.75|       432157.0|         453424.0|        885581.0|\n",
      "+----------+--------------+------------------+---------------+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_state = df.select('State Code', 'State', \\\n",
    "                          'Median Age', 'Male Population', \\\n",
    "                          'Female Population', 'Total Population') \\\n",
    "                    .distinct()\n",
    "new_columns = ['state_code', 'state_name', 'median_age', 'male_population', 'female_population', 'total_population']\n",
    "dim_state = rename_columns(dim_state, new_columns)\n",
    "# dim_state = dim_state.filter(dim_state.state_code.isNotNull())\n",
    "dim_state.groupBy(\"state_code\", \"state_name\") \\\n",
    "    .agg(expr('percentile(median_age, array(0.5))')[0].alias('median_age'),\n",
    "      sum(\"male_population\").alias(\"male_population\"), \n",
    "      sum(\"female_population\").alias(\"female_population\"), \n",
    "      sum(\"total_population\").alias(\"total_population\"))  \\\n",
    "    .show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_state = df.select('State Code', 'State', \\\n",
    "                          'Median Age', 'Male Population', \\\n",
    "                          'Female Population', 'Total Population') \\\n",
    "                    .distinct()\n",
    "new_columns = ['state_code', 'state_name', 'median_age', 'male_population', 'female_population', 'total_population']\n",
    "dim_state = rename_columns(dim_state, new_columns)\n",
    "dim_state.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: fact_immigration is not empty: total 203307 records.\n",
      "Table fact_immigration does not have null value for cic_id key column .\n",
      "Schema of this table:\n",
      "root\n",
      " |-- cic_id: double (nullable = true)\n",
      " |-- arrival_year: double (nullable = true)\n",
      " |-- arrival_month: double (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- mode: double (nullable = true)\n",
      " |-- visa: double (nullable = true)\n",
      " |-- immigration_id: long (nullable = false)\n",
      " |-- country: string (nullable = false)\n",
      "\n",
      "Table: dim_time is not empty: total 228 records.\n",
      "Table dim_time does not have null value for date key column .\n",
      "Schema of this table:\n",
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n",
      "Table: dim_personal_information is not empty: total 203307 records.\n",
      "Table dim_personal_information does not have null value for cic_id key column .\n",
      "Schema of this table:\n",
      "root\n",
      " |-- cic_id: double (nullable = true)\n",
      " |-- citizen_country: double (nullable = true)\n",
      " |-- residence_country: double (nullable = true)\n",
      " |-- birth_year: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- immi_personal_id: long (nullable = false)\n",
      "\n",
      "Table: dim_state is not empty: total 596 records.\n",
      "Table dim_state does not have null value for state_code key column .\n",
      "Schema of this table:\n",
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- state_name: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df = {'fact_immigration': fact_immigration, \\\n",
    "              'dim_time': dim_time, \\\n",
    "              'dim_personal_information': dim_personal_information, \\\n",
    "              'dim_state': dim_state}\n",
    "for df_name, df in all_df.items():\n",
    "    num_records = df.count()\n",
    "    if num_records <= 0:\n",
    "        raise ValueError(f\"Table {df_name} is empty!\")\n",
    "    else:\n",
    "        print(f\"Table: {df_name} is not empty: total {num_records} records.\")\n",
    "        \n",
    "    num_null_key_records = df.filter(df[df.columns[0]].isNull()).count()\n",
    "    if num_null_key_records > 0:\n",
    "        raise ValueError(f\"Table {df_name} have null value for {df.columns[0]} key column !\")\n",
    "    else:\n",
    "        print(f\"Table {df_name} does not have null value for {df.columns[0]} key column .\")\n",
    "    \n",
    "    print(\"Schema of this table:\")\n",
    "    df.printSchema()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_immigration.createOrReplaceTempView(\"fact_immigration_table\")\n",
    "dim_time.createOrReplaceTempView(\"dim_time_table\")\n",
    "dim_personal_information.createOrReplaceTempView(\"dim_personal_information_table\")\n",
    "dim_state.createOrReplaceTempView(\"dim_state_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033070\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")\n",
    "# Some analysis query example:\n",
    "# Number of immigrants go to Maryland state:\n",
    "num_immigrants_of_Maryland_state = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM fact_immigration_table AS fit\n",
    "    JOIN dim_state_table AS dst\n",
    "    WHERE dst.state_name == \"Maryland\"\n",
    "    \"\"\")\n",
    "print(num_immigrants_of_Maryland_state.collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6912438\n"
     ]
    }
   ],
   "source": [
    "# Number of immigrants on Saturday:\n",
    "num_immigrants_on_Saturday = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM fact_immigration_table AS fit\n",
    "    JOIN dim_time_table AS dt\n",
    "    WHERE dt.weekday == 6\n",
    "    \"\"\")\n",
    "print(num_immigrants_on_Saturday.collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5895903\n"
     ]
    }
   ],
   "source": [
    "# Number of immigrants on Monday:\n",
    "num_immigrants_on_Monday = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM fact_immigration_table AS fit\n",
    "    JOIN dim_time_table AS dt\n",
    "    WHERE dt.weekday == 1\n",
    "    \"\"\")\n",
    "print(num_immigrants_on_Monday.collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
